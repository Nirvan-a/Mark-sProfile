"""
ç»“æœç­›é€‰æ™ºèƒ½ä½“
ä»æ£€ç´¢ç»“æœä¸­ç­›é€‰å‡ºæœ€ç›¸å…³ã€æœ€å®Œæ•´çš„ä¿¡æ¯
"""
import os
from typing import List, Dict, Any, Optional

try:
    from langchain_openai import ChatOpenAI
except ImportError:
    from langchain_community.chat_models import ChatOpenAI


class ResultFilterAgentError(Exception):
    """ç»“æœç­›é€‰æ™ºèƒ½ä½“é”™è¯¯"""
    pass


class ResultFilterAgent:
    """ç»“æœç­›é€‰æ™ºèƒ½ä½“ - ä»æ£€ç´¢ç»“æœä¸­ç­›é€‰å‡ºæœ€ç¬¦åˆè¦æ±‚çš„ä¿¡æ¯"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç»“æœç­›é€‰æ™ºèƒ½ä½“"""
        # ç¡®ä¿åŠ è½½ .env æ–‡ä»¶
        from dotenv import load_dotenv
        from pathlib import Path
        env_path = Path(__file__).parent.parent.parent.parent / ".env"
        load_dotenv(dotenv_path=env_path, override=False)
        
        api_key = os.getenv("DASHSCOPE_API_KEY")
        if not api_key:
            raise ResultFilterAgentError("DASHSCOPE_API_KEY æœªé…ç½®")
        
        self.llm = ChatOpenAI(
            model="qwen-plus",
            api_key=api_key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            temperature=0.3,  # è¾ƒä½æ¸©åº¦ï¼Œæ›´ç¡®å®šæ€§
        )
    
    def filter_results(
        self,
        search_results: List[Dict[str, Any]],
        section: Dict[str, Any],
        search_queries: List[str],
        outline: str,
        target_count: Optional[int] = None,
        missing_points: Optional[List[str]] = None
    ) -> List[Dict[str, Any]]:
        """
        ä»æ£€ç´¢ç»“æœä¸­ç­›é€‰å‡ºæœ€ç›¸å…³ã€æœ€å®Œæ•´çš„ä¿¡æ¯
        
        Args:
            search_results: æ£€ç´¢ç»“æœåˆ—è¡¨
            section: å½“å‰ç« èŠ‚ä¿¡æ¯
            search_queries: ä½¿ç”¨çš„æ£€ç´¢è¯­å¥åˆ—è¡¨
            outline: å®Œæ•´å¤§çº²
            target_count: ç›®æ ‡ç­›é€‰æ•°é‡ï¼ˆé»˜è®¤é€‰å‡ºä¸€åŠï¼‰
            missing_points: ä¿¡æ¯ç¼ºå¤±ç‚¹åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœæœ‰ï¼Œå°†ä¼˜å…ˆç­›é€‰èƒ½è¦†ç›–è¿™äº›ç¼ºå¤±ç‚¹çš„ç»“æœ
        
        Returns:
            ç­›é€‰åçš„ç»“æœåˆ—è¡¨
        """
        if not search_results:
            return []
        
        # å¦‚æœæœªæŒ‡å®šç›®æ ‡æ•°é‡ï¼Œé€‰å‡ºä¸€åŠ
        if target_count is None:
            target_count = max(1, len(search_results) // 2)
        target_count = min(target_count, len(search_results))
        
        level1_title = section.get("level1_title", "")
        level2_title = section.get("level2_title", "")
        
        # æ ¹æ®æ˜¯å¦æœ‰ç¼ºå¤±ç‚¹ï¼Œæ„å»ºä¸åŒçš„ç­›é€‰æ ‡å‡†
        if missing_points:
            system_prompt = """ä½ æ˜¯ä¸€ä½ä¿¡æ¯ç­›é€‰ä¸“å®¶ï¼Œæ“…é•¿ä»å¤§é‡æ£€ç´¢ç»“æœä¸­ç­›é€‰å‡ºæœ€ç›¸å…³ã€æœ€å®Œæ•´çš„ä¿¡æ¯ã€‚

**ç­›é€‰æ ‡å‡†ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰**ï¼š
1. **è¦†ç›–ç¼ºå¤±ç‚¹ï¼ˆæœ€é‡è¦ï¼‰**ï¼šä¼˜å…ˆé€‰æ‹©èƒ½å¤Ÿè¦†ç›–æˆ–éƒ¨åˆ†è¦†ç›–ä¿¡æ¯ç¼ºå¤±ç‚¹çš„ç»“æœã€‚ä¿¡æ¯ç¼ºå¤±ç‚¹æ˜¯ç»è¿‡ä¿¡æ¯å……è¶³æ€§è¯„ä¼°åç¡®å®šçš„å…³é”®ä¿¡æ¯ç¼ºå£ï¼Œç­›é€‰ç»“æœåº”è¯¥ä¼˜å…ˆå¡«è¡¥è¿™äº›ç¼ºå£
2. **ç›¸å…³æ€§**ï¼šä¿¡æ¯å¿…é¡»ä¸ç« èŠ‚ä¸»é¢˜é«˜åº¦ç›¸å…³ï¼Œç›´æ¥æ¶‰åŠç« èŠ‚çš„æ ¸å¿ƒå†…å®¹
3. **å®Œæ•´æ€§**ï¼šä¿¡æ¯åº”è¯¥å®Œæ•´ã€è¯¦ç»†ï¼ŒåŒ…å«å…·ä½“çš„ç»†èŠ‚å’Œäº‹å®ï¼Œèƒ½å¤Ÿæ”¯æ’‘ç« èŠ‚å†™ä½œ
4. **ä¿¡æ¯è´¨é‡**ï¼šä¿¡æ¯åº”è¯¥å‡†ç¡®ã€å¯é ï¼Œæ¥è‡ªå¯ä¿¡æ¥æº
5. **å¤šæ ·æ€§**ï¼šå°½é‡é€‰æ‹©æä¾›ä¸åŒè§’åº¦æˆ–ä¸åŒç»´åº¦çš„ä¿¡æ¯ï¼Œç¡®ä¿ç­›é€‰ç»“æœèƒ½å¤Ÿå…±åŒè¦†ç›–æ‰€æœ‰ç¼ºå¤±ç‚¹
6. **äº’è¡¥æ€§**ï¼šä¼˜å…ˆé€‰æ‹©æä¾›ä¸åŒç¼ºå¤±ç‚¹ä¿¡æ¯çš„ç»“æœï¼Œé¿å…é‡å¤

**è¾“å‡ºæ ¼å¼**ï¼š
è¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯ä¸¥æ ¼çš„JSONæ•°ç»„ï¼ŒåŒ…å«ç­›é€‰å‡ºçš„ç»“æœç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰ï¼š
[0, 2, 5, ...]

è¯·ä»æ‰€æœ‰ç»“æœä¸­é€‰å‡ºæœ€ç›¸å…³ã€æœ€å®Œæ•´çš„ {target_count} ä¸ªç»“æœï¼Œ**ä¼˜å…ˆé€‰æ‹©èƒ½å¤Ÿè¦†ç›–ä¿¡æ¯ç¼ºå¤±ç‚¹çš„ç»“æœ**ï¼Œç¡®ä¿è¿™äº›ç»“æœèƒ½å¤Ÿå…±åŒè¦†ç›–æ‰€æœ‰ç¼ºå¤±çš„ä¿¡æ¯ç‚¹ã€‚""".format(target_count=target_count)
        else:
            system_prompt = """ä½ æ˜¯ä¸€ä½ä¿¡æ¯ç­›é€‰ä¸“å®¶ï¼Œæ“…é•¿ä»å¤§é‡æ£€ç´¢ç»“æœä¸­ç­›é€‰å‡ºæœ€ç›¸å…³ã€æœ€å®Œæ•´çš„ä¿¡æ¯ã€‚

**ç­›é€‰æ ‡å‡†ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰**ï¼š
1. **ç›¸å…³æ€§ï¼ˆæœ€é‡è¦ï¼‰**ï¼šä¿¡æ¯å¿…é¡»ä¸ç« èŠ‚ä¸»é¢˜é«˜åº¦ç›¸å…³ï¼Œç›´æ¥æ¶‰åŠç« èŠ‚çš„æ ¸å¿ƒå†…å®¹
2. **å®Œæ•´æ€§**ï¼šä¿¡æ¯åº”è¯¥å®Œæ•´ã€è¯¦ç»†ï¼ŒåŒ…å«å…·ä½“çš„ç»†èŠ‚å’Œäº‹å®ï¼Œèƒ½å¤Ÿæ”¯æ’‘ç« èŠ‚å†™ä½œ
3. **ä¿¡æ¯è´¨é‡**ï¼šä¿¡æ¯åº”è¯¥å‡†ç¡®ã€å¯é ï¼Œæ¥è‡ªå¯ä¿¡æ¥æº
4. **å¤šæ ·æ€§**ï¼šå°½é‡é€‰æ‹©æä¾›ä¸åŒè§’åº¦æˆ–ä¸åŒç»´åº¦çš„ä¿¡æ¯ï¼Œé¿å…é‡å¤
5. **æ–°é¢–æ€§**ï¼šä¼˜å…ˆé€‰æ‹©æä¾›æ–°è§’åº¦æˆ–æ–°ä¿¡æ¯çš„ç»“æœï¼Œä¸å·²æœ‰ä¿¡æ¯äº’è¡¥

**è¾“å‡ºæ ¼å¼**ï¼š
è¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯ä¸¥æ ¼çš„JSONæ•°ç»„ï¼ŒåŒ…å«ç­›é€‰å‡ºçš„ç»“æœç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰ï¼š
[0, 2, 5, ...]

è¯·ä»æ‰€æœ‰ç»“æœä¸­é€‰å‡ºæœ€ç›¸å…³ã€æœ€å®Œæ•´çš„ {target_count} ä¸ªç»“æœï¼Œç¡®ä¿è¿™äº›ç»“æœèƒ½å¤Ÿå…±åŒè¦†ç›–ç« èŠ‚æ‰€éœ€çš„ä¸»è¦ä¿¡æ¯ç‚¹ã€‚""".format(target_count=target_count)

        # æ ¼å¼åŒ–æ£€ç´¢ç»“æœ
        results_text = ""
        for i, result in enumerate(search_results):
            title = result.get("title", result.get("filename", "æ— æ ‡é¢˜"))
            content = result.get("content", "")
            # åªå–å300å­—ç¬¦ï¼ˆå¦‚æœå†…å®¹é•¿åº¦è¶…è¿‡300å­—ç¬¦ï¼‰
            if len(content) > 300:
                content = "..." + content[-300:]  # å–å300å­—ç¬¦ï¼Œå‰é¢åŠ çœç•¥å·
            source = result.get("source", result.get("url", "æœªçŸ¥æ¥æº"))
            results_text += f"\n[ç»“æœ {i}]\næ ‡é¢˜: {title}\næ¥æº: {source}\nå†…å®¹: {content}\n"

        # æ„å»ºç”¨æˆ·æç¤ºï¼Œå¦‚æœæœ‰ç¼ºå¤±ç‚¹åˆ™åŠ å…¥ç¼ºå¤±ç‚¹ä¿¡æ¯
        user_prompt_parts = [
            f"è¯·ä»ä»¥ä¸‹æ£€ç´¢ç»“æœä¸­ç­›é€‰å‡ºæœ€ç›¸å…³ã€æœ€å®Œæ•´çš„ {target_count} ä¸ªç»“æœï¼š",
            "",
            "ç« èŠ‚ä¿¡æ¯ï¼š",
            f"- ä¸€çº§æ ‡é¢˜ï¼š{level1_title}",
            f"- äºŒçº§æ ‡é¢˜ï¼š{level2_title}",
            "",
            "ä½¿ç”¨çš„æ£€ç´¢è¯­å¥ï¼š",
        ]
        user_prompt_parts.extend([f"- {q}" for q in search_queries])
        
        if missing_points:
            user_prompt_parts.extend([
                "",
                "ä¿¡æ¯ç¼ºå¤±ç‚¹ï¼ˆç»è¿‡ä¿¡æ¯å……è¶³æ€§è¯„ä¼°ç¡®å®šçš„å…³é”®ä¿¡æ¯ç¼ºå£ï¼Œç­›é€‰ç»“æœåº”ä¼˜å…ˆè¦†ç›–è¿™äº›ç¼ºå¤±ç‚¹ï¼‰ï¼š",
            ])
            for i, point in enumerate(missing_points, 1):
                user_prompt_parts.append(f"{i}. {point}")
        
        user_prompt_parts.extend([
            "",
            "å®Œæ•´å¤§çº²ï¼š",
            outline,
            "",
            f"æ£€ç´¢ç»“æœï¼ˆå…±{len(search_results)}æ¡ï¼‰ï¼š",
            results_text,
            "",
            "è¯·è¿”å›ç­›é€‰å‡ºçš„ç»“æœç´¢å¼•æ•°ç»„ï¼ˆJSONæ ¼å¼ï¼‰ï¼š",
        ])
        
        user_prompt = "\n".join(user_prompt_parts)

        try:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ]
            
            print(f"\n{'='*60}")
            print(f"ğŸ” [ResultFilterAgent] ç­›é€‰æ£€ç´¢ç»“æœ")
            print(f"{'='*60}")
            print(f"ç« èŠ‚: {level1_title} - {level2_title}")
            print(f"åŸå§‹ç»“æœæ•°: {len(search_results)}")
            print(f"ç›®æ ‡ç­›é€‰æ•°: {target_count}")
            if missing_points:
                print(f"ç¼ºå¤±ç‚¹æ•°é‡: {len(missing_points)}")
                print(f"ç¼ºå¤±ç‚¹: {missing_points[:3]}..." if len(missing_points) > 3 else f"ç¼ºå¤±ç‚¹: {missing_points}")
            print(f"å¼€å§‹è¯·æ±‚...")
            
            response = self.llm.invoke(messages)
            content = response.content.strip()
            
            print(f"âœ… [ResultFilterAgent] LLM å“åº”å®Œæˆ")
            
            # æå–JSONæ•°ç»„
            content = self._extract_json_array(content)
            
            # è§£æJSON
            import json
            selected_indices = json.loads(content)
            
            # éªŒè¯å’Œè§„èŒƒåŒ–
            if not isinstance(selected_indices, list):
                raise ValueError("è¿”å›çš„ä¸æ˜¯æ•°ç»„æ ¼å¼")
            
            # è½¬æ¢ä¸ºæ•´æ•°ç´¢å¼•ï¼Œå¹¶è¿‡æ»¤æ— æ•ˆç´¢å¼•
            valid_indices = []
            for idx in selected_indices:
                try:
                    idx = int(idx)
                    if 0 <= idx < len(search_results):
                        valid_indices.append(idx)
                except (ValueError, TypeError):
                    continue
            
            # å»é‡å¹¶ä¿æŒé¡ºåº
            seen = set()
            unique_indices = []
            for idx in valid_indices:
                if idx not in seen:
                    seen.add(idx)
                    unique_indices.append(idx)
            
            # é™åˆ¶æ•°é‡
            unique_indices = unique_indices[:target_count]
            
            # æ ¹æ®ç´¢å¼•ç­›é€‰ç»“æœ
            filtered_results = [search_results[i] for i in unique_indices]
            
            print(f"âœ… ç­›é€‰å®Œæˆ: ä» {len(search_results)} ä¸ªç»“æœä¸­é€‰å‡º {len(filtered_results)} ä¸ª")
            
            return filtered_results
            
        except Exception as e:
            print(f"âš ï¸  ç»“æœç­›é€‰å¤±è´¥: {e}ï¼Œè¿”å›å‰ {target_count} ä¸ªç»“æœ")
            # å›é€€ï¼šè¿”å›å‰ target_count ä¸ªç»“æœ
            return search_results[:target_count]
    
    def _extract_json_array(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–JSONæ•°ç»„"""
        text = text.strip()
        
        # å¦‚æœåŒ…å«markdownä»£ç å—
        if text.startswith("```"):
            lines = text.split("\n")
            json_start = 0
            json_end = len(lines)
            
            for i, line in enumerate(lines):
                if line.strip().startswith("```"):
                    if json_start == 0:
                        json_start = i + 1
                    else:
                        json_end = i
                        break
            
            text = "\n".join(lines[json_start:json_end])
        
        # æŸ¥æ‰¾JSONæ•°ç»„
        start_idx = text.find("[")
        end_idx = text.rfind("]")
        
        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            text = text[start_idx:end_idx + 1]
        
        return text.strip()

